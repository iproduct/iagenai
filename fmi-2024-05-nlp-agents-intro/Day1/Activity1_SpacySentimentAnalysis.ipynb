{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyPM6cZs9OgrPsOlHcRi3MTK",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/angelaaaateng/AIR_AI_Engineering_Course_2024/blob/main/Day1/Activity1_SpacySentimentAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "me_nZi_6vW12",
    "outputId": "b04517ae-2475-4868-fc22-89d53e3abd9f",
    "ExecuteTime": {
     "end_time": "2025-12-17T15:43:01.557501300Z",
     "start_time": "2025-12-17T15:43:01.491226700Z"
    }
   },
   "source": [
    "# Install necessary libraries\n",
    "# !pip install spacy spacytextblob\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# Documentation: https://spacy.io/universe/project/spacy-textblob"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "# Import necessary libraries\n",
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "import pandas as pd\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Apply tqdm to pandas for progress tracking\n",
    "tqdm.pandas()\n"
   ],
   "metadata": {
    "id": "HLt6Vg-Kwe-B",
    "ExecuteTime": {
     "end_time": "2025-12-17T15:43:27.138116600Z",
     "start_time": "2025-12-17T15:43:01.567597200Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the SpaCy language model and add the textblob component for sentiment analysis\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"spacytextblob\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wxk5EyVIwkrn",
    "outputId": "70637500-f74a-4a37-9b2e-4b91c47973ac",
    "ExecuteTime": {
     "end_time": "2025-12-17T15:43:31.196215300Z",
     "start_time": "2025-12-17T15:43:27.435460800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacytextblob.spacytextblob.SpacyTextBlob at 0x174ae516bd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "# Optimized function for preprocessing the text using SpaCy\n",
    "def preprocess_text(text):\n",
    "    # Process the text using the SpaCy pipeline (no need to manually lowercase, SpaCy handles this)\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Use a list comprehension to filter and lemmatize tokens\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "\n",
    "    # Join the tokens back into a single string\n",
    "    return \" \".join(tokens)\n"
   ],
   "metadata": {
    "id": "4rMCc-oGxH0b",
    "ExecuteTime": {
     "end_time": "2025-12-17T15:43:31.268963800Z",
     "start_time": "2025-12-17T15:43:31.240817200Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "# Function to classify the sentiment score as Positive, Negative, or Neutral\n",
    "def classify_sentiment(score):\n",
    "    if score > 0:\n",
    "        return \"positive\"\n",
    "    elif score < 0:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\""
   ],
   "metadata": {
    "id": "ArWJgi61x1-p",
    "ExecuteTime": {
     "end_time": "2025-12-17T15:43:31.286766700Z",
     "start_time": "2025-12-17T15:43:31.269964200Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the IMDB dataset from GitHub\n",
    "url = \"https://github.com/angelaaaateng/AIR_AI_Engineering_Course_2024/raw/refs/heads/main/Datasets/IMDB_Dataset.csv\"\n",
    "df = pd.read_csv(url)"
   ],
   "metadata": {
    "id": "2AgIXR8oyURA",
    "ExecuteTime": {
     "end_time": "2025-12-17T15:43:39.602997800Z",
     "start_time": "2025-12-17T15:43:31.288873700Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "# Randomly sample 1000 entries from the dataset\n",
    "df_sampled = df.sample(n=1000, random_state=42)\n",
    "# takes a long time to process"
   ],
   "metadata": {
    "id": "f8UO_cNo-Yek",
    "ExecuteTime": {
     "end_time": "2025-12-17T15:43:39.783500700Z",
     "start_time": "2025-12-17T15:43:39.668256Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "df.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "KMPznekDyVzm",
    "outputId": "e877c640-fc60-4fa1-eb3d-d6d6fc7ae0a8",
    "ExecuteTime": {
     "end_time": "2025-12-17T15:43:39.813774200Z",
     "start_time": "2025-12-17T15:43:39.784500400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "print(df.size)\n",
    "print(df_sampled.size)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oKcnz_2y8yrI",
    "outputId": "3633fb7a-8887-4f2b-895b-71c959038189",
    "ExecuteTime": {
     "end_time": "2025-12-17T15:43:39.826823400Z",
     "start_time": "2025-12-17T15:43:39.815811300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "2000\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "- A sentiment score greater than 0 will be labeled as \"Positive\".\n",
    "- A sentiment score less than 0 will be labeled as \"Negative\".\n",
    "- A sentiment score of exactly 0 will be labeled as \"Neutral\"."
   ],
   "metadata": {
    "id": "UzZcOIvexYNM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Preprocess the reviews\n",
    "# df['cleaned_review'] = df['review'].apply(preprocess_text)\n",
    "# Preprocess the reviews with a progress bar\n",
    "df_sampled['cleaned_review'] = df_sampled['review'].progress_apply(preprocess_text)\n",
    "df_sampled.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "SFarV9jAxNzT",
    "outputId": "6f373e34-a7c7-4e03-b56c-567f9963c17c",
    "ExecuteTime": {
     "end_time": "2025-12-17T15:44:37.307893400Z",
     "start_time": "2025-12-17T15:43:39.922749700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:57<00:00, 17.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "33553  I really liked this Summerslam due to the look...  positive   \n",
       "9427   Not many television shows appeal to quite as m...  positive   \n",
       "199    The film quickly gets to a major chase scene w...  negative   \n",
       "12447  Jane Austen would definitely approve of this o...  positive   \n",
       "39489  Expectations were somewhat high for me when I ...  negative   \n",
       "\n",
       "                                          cleaned_review  \n",
       "33553  like Summerslam look arena curtain look overal...  \n",
       "9427   television show appeal different kind fan like...  \n",
       "199    film quickly get major chase scene increase de...  \n",
       "12447  Jane Austen definitely approve Paltrow awesome...  \n",
       "39489  expectation somewhat high go movie think Steve...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33553</th>\n",
       "      <td>I really liked this Summerslam due to the look...</td>\n",
       "      <td>positive</td>\n",
       "      <td>like Summerslam look arena curtain look overal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9427</th>\n",
       "      <td>Not many television shows appeal to quite as m...</td>\n",
       "      <td>positive</td>\n",
       "      <td>television show appeal different kind fan like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>The film quickly gets to a major chase scene w...</td>\n",
       "      <td>negative</td>\n",
       "      <td>film quickly get major chase scene increase de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12447</th>\n",
       "      <td>Jane Austen would definitely approve of this o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Jane Austen definitely approve Paltrow awesome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39489</th>\n",
       "      <td>Expectations were somewhat high for me when I ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>expectation somewhat high go movie think Steve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "# Perform sentiment analysis on the preprocessed reviews\n",
    "df_sampled['sentiment_score'] = df_sampled['cleaned_review'].progress_apply(lambda review: nlp(review)._.polarity)\n",
    "df_sampled.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "C7oVSE4DyeJN",
    "outputId": "2a585cb3-7390-447a-b475-495142cad3a8",
    "ExecuteTime": {
     "end_time": "2025-12-17T15:44:40.876177900Z",
     "start_time": "2025-12-17T15:44:38.365983800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<00:30, 33.25it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "[E046] Can't retrieve unregistered extension attribute 'polarity'. Did you forget to call the `set_extension` method?",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Perform sentiment analysis on the preprocessed reviews\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m df_sampled[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msentiment_score\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdf_sampled\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcleaned_review\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprogress_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mreview\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mnlp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreview\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpolarity\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m df_sampled\u001B[38;5;241m.\u001B[39mhead()\n",
      "File \u001B[1;32mD:\\Programs\\Python312\\Lib\\site-packages\\tqdm\\std.py:917\u001B[0m, in \u001B[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001B[1;34m(df, func, *args, **kwargs)\u001B[0m\n\u001B[0;32m    914\u001B[0m \u001B[38;5;66;03m# Apply the provided function (in **kwargs)\u001B[39;00m\n\u001B[0;32m    915\u001B[0m \u001B[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001B[39;00m\n\u001B[0;32m    916\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 917\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf_function\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwrapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    918\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    919\u001B[0m     t\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32mD:\\CourseIAGenAI\\git\\iagenai\\fmi-2024-05-nlp-agents-intro\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001B[0m, in \u001B[0;36mSeries.apply\u001B[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001B[0m\n\u001B[0;32m   4789\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[0;32m   4790\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   4791\u001B[0m     func: AggFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4796\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   4797\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[0;32m   4798\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   4799\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[0;32m   4800\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4915\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[0;32m   4916\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m   4917\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   4918\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4919\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4920\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4921\u001B[0m \u001B[43m        \u001B[49m\u001B[43mby_row\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mby_row\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4922\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4923\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m-> 4924\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\CourseIAGenAI\\git\\iagenai\\fmi-2024-05-nlp-agents-intro\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1424\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_compat()\n\u001B[0;32m   1426\u001B[0m \u001B[38;5;66;03m# self.func is Callable\u001B[39;00m\n\u001B[1;32m-> 1427\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\CourseIAGenAI\\git\\iagenai\\fmi-2024-05-nlp-agents-intro\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1501\u001B[0m \u001B[38;5;66;03m# row-wise access\u001B[39;00m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m \u001B[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001B[39;00m\n\u001B[0;32m   1504\u001B[0m \u001B[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001B[39;00m\n\u001B[0;32m   1505\u001B[0m \u001B[38;5;66;03m#  Categorical (GH51645).\u001B[39;00m\n\u001B[0;32m   1506\u001B[0m action \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj\u001B[38;5;241m.\u001B[39mdtype, CategoricalDtype) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1507\u001B[0m mapped \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_values\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1508\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmapper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcurried\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\n\u001B[0;32m   1509\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[0;32m   1512\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[0;32m   1513\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[0;32m   1514\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[1;32mD:\\CourseIAGenAI\\git\\iagenai\\fmi-2024-05-nlp-agents-intro\\.venv\\Lib\\site-packages\\pandas\\core\\base.py:921\u001B[0m, in \u001B[0;36mIndexOpsMixin._map_values\u001B[1;34m(self, mapper, na_action, convert)\u001B[0m\n\u001B[0;32m    918\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, ExtensionArray):\n\u001B[0;32m    919\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mmap(mapper, na_action\u001B[38;5;241m=\u001B[39mna_action)\n\u001B[1;32m--> 921\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43malgorithms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_action\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\CourseIAGenAI\\git\\iagenai\\fmi-2024-05-nlp-agents-intro\\.venv\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001B[0m, in \u001B[0;36mmap_array\u001B[1;34m(arr, mapper, na_action, convert)\u001B[0m\n\u001B[0;32m   1741\u001B[0m values \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m na_action \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1743\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1745\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mmap_infer_mask(\n\u001B[0;32m   1746\u001B[0m         values, mapper, mask\u001B[38;5;241m=\u001B[39misna(values)\u001B[38;5;241m.\u001B[39mview(np\u001B[38;5;241m.\u001B[39muint8), convert\u001B[38;5;241m=\u001B[39mconvert\n\u001B[0;32m   1747\u001B[0m     )\n",
      "File \u001B[1;32mlib.pyx:2972\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\Programs\\Python312\\Lib\\site-packages\\tqdm\\std.py:912\u001B[0m, in \u001B[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    906\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    907\u001B[0m     \u001B[38;5;66;03m# update tbar correctly\u001B[39;00m\n\u001B[0;32m    908\u001B[0m     \u001B[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001B[39;00m\n\u001B[0;32m    909\u001B[0m     \u001B[38;5;66;03m# on the first column/row to decide whether it can\u001B[39;00m\n\u001B[0;32m    910\u001B[0m     \u001B[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001B[39;00m\n\u001B[0;32m    911\u001B[0m     t\u001B[38;5;241m.\u001B[39mupdate(n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m t\u001B[38;5;241m.\u001B[39mtotal \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mn \u001B[38;5;241m<\u001B[39m t\u001B[38;5;241m.\u001B[39mtotal \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m--> 912\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[11], line 2\u001B[0m, in \u001B[0;36m<lambda>\u001B[1;34m(review)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Perform sentiment analysis on the preprocessed reviews\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m df_sampled[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msentiment_score\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df_sampled[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcleaned_review\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mprogress_apply(\u001B[38;5;28;01mlambda\u001B[39;00m review: \u001B[43mnlp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreview\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpolarity\u001B[49m)\n\u001B[0;32m      3\u001B[0m df_sampled\u001B[38;5;241m.\u001B[39mhead()\n",
      "File \u001B[1;32mD:\\CourseIAGenAI\\git\\iagenai\\fmi-2024-05-nlp-agents-intro\\.venv\\Lib\\site-packages\\spacy\\tokens\\underscore.py:48\u001B[0m, in \u001B[0;36mUnderscore.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getattr__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m     47\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_extensions:\n\u001B[1;32m---> 48\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(Errors\u001B[38;5;241m.\u001B[39mE046\u001B[38;5;241m.\u001B[39mformat(name\u001B[38;5;241m=\u001B[39mname))\n\u001B[0;32m     49\u001B[0m     default, method, getter, setter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_extensions[name]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m getter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mAttributeError\u001B[0m: [E046] Can't retrieve unregistered extension attribute 'polarity'. Did you forget to call the `set_extension` method?"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "# Classify the sentiment based on the score\n",
    "df_sampled['sentiment_label'] = df_sampled['sentiment_score'].progress_apply(classify_sentiment)\n",
    "df_sampled.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "sOM1KfKnyiHL",
    "outputId": "45a1a56d-e253-49b7-f071-3973951580b5"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Display the results\n",
    "df_sampled[['review', 'cleaned_review', 'sentiment_score', 'sentiment_label']].head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "fg8VBn8DylSA",
    "outputId": "74e791ff-558b-4fe0-98c9-0c52a34d33f8"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Documentation: [Spacy's Textblob Implementation](https://spacy.io/universe/project/spacy-textblob); Textblob's [Documentation](https://textblob.readthedocs.io/en/dev/)\n",
    "\n",
    "**TextBlob** is a simple, easy-to-use Python library for processing textual data. It provides a consistent API for diving into common natural language processing (NLP) tasks, such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.\n",
    "\n",
    "### Key Features of TextBlob:\n",
    "\n",
    "1. **Sentiment Analysis**:\n",
    "   - One of the most popular features of TextBlob is its ability to perform sentiment analysis. It uses two key measures:\n",
    "     - **Polarity**: This is a float value within the range [-1.0, 1.0], where:\n",
    "       - `-1` represents a very negative sentiment.\n",
    "       - `0` represents a neutral sentiment.\n",
    "       - `+1` represents a very positive sentiment.\n",
    "     - **Subjectivity**: This is a float within the range [0.0, 1.0] that represents the degree of subjectivity in the text.\n",
    "       - `0` means the text is very objective (fact-based).\n",
    "       - `1` means the text is highly subjective (opinion-based).\n",
    "\n",
    "2. **Part-of-Speech Tagging**:\n",
    "   - TextBlob can tag parts of speech, such as nouns, verbs, adjectives, etc. For example, it can classify the words in a sentence to understand the structure and function of each word.\n",
    "\n",
    "3. **Noun Phrase Extraction**:\n",
    "   - It can extract noun phrases (a group of words that act as a noun, like \"machine learning model\") to help understand the focus of a text.\n",
    "\n",
    "4. **Translation and Language Detection**:\n",
    "   - TextBlob has built-in capabilities to translate between languages and detect the language of the given text using the Google Translate API.\n",
    "\n",
    "5. **Classification**:\n",
    "   - TextBlob supports text classification, which allows you to classify text into different categories based on training data.\n",
    "\n",
    "### How Does TextBlob Perform Sentiment Analysis?\n",
    "TextBlob’s sentiment analysis is based on a tool called **Pattern**, which is a web mining module for Python. The Pattern library has pre-trained models for sentiment analysis and subjectivity detection. TextBlob utilizes these pre-trained models to assess sentiment without requiring further training, making it ideal for simpler, out-of-the-box sentiment tasks.\n",
    "\n",
    "In the context of **SpaCy**, `spacytextblob` acts as a bridge that incorporates TextBlob's capabilities (specifically for sentiment analysis) into SpaCy’s powerful language model pipeline. This allows users to combine the strengths of SpaCy (fast, tokenization, and parsing) with TextBlob's sentiment analysis feature.\n",
    "\n",
    "### Why Use TextBlob?\n",
    "\n",
    "1. **Ease of Use**: TextBlob simplifies many of the common NLP tasks with its intuitive API.\n",
    "2. **Quick Start**: It works well for beginners who want to quickly try out basic NLP tasks without requiring complex configurations or machine learning model setups.\n",
    "3. **Lightweight**: TextBlob is light compared to larger NLP libraries, making it perfect for smaller tasks or rapid prototyping.\n",
    "\n",
    "### Limitations:\n",
    "- **Shallow Analysis**: While great for quick tasks, TextBlob's sentiment analysis and language understanding are relatively shallow compared to more complex models like transformers or BERT-based models.\n",
    "- **Accuracy**: It uses simple, rule-based methods and can be less accurate in some NLP tasks, especially with nuanced text or in situations where deep contextual understanding is needed.\n",
    "\n",
    "TextBlob is especially suited for quick sentiment analysis, simple text processing tasks, and learning purposes, but for more advanced applications, you would likely move towards deeper models or tools like SpaCy, BERT, or GPT."
   ],
   "metadata": {
    "id": "GjtI5aCMy1n0"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "nmk_1n1JynCN"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}

{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Simple Transformer Language Model.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "authorship_tag": "ABX9TyOEWirarSiFWRClhLdkaXby",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jalammar/jalammar.github.io/blob/master/notebooks/Simple_Transformer_Language_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SfaGYwr6QGl0",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "outputId": "45caa369-4bda-420d-f407-1002204c6e83"
   },
   "source": [
    "!pip install transformers"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SKOHXyzNQ5Wa",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\") \n",
    "model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\", output_hidden_states=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zdQBaZZcQ_Sa",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "outputId": "4cc3dbf5-922d-4eda-b47e-75e8adbc96e2",
    "ExecuteTime": {
     "end_time": "2024-11-21T15:48:44.184954Z",
     "start_time": "2024-11-21T15:48:44.138595Z"
    }
   },
   "source": [
    "text = \"The Shawshank\"\n",
    "\n",
    "# Tokenize the input string\n",
    "input = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "\n",
    "# Run the model\n",
    "output = model.generate(input, max_length=5, do_sample=False)\n",
    "\n",
    "# Print the output\n",
    "print('\\n',tokenizer.decode(output[0]))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The Shawshank Redemption\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "m8m1rK3gNNW4",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "61da2785-cd28-4b00-84bf-ac65deea8d57"
   },
   "source": [
    "# Print the token ides (of the input and output)\n",
    "output"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tProbSeTJATA",
    "colab_type": "text"
   },
   "source": [
    "## From words to vectors and back"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Dy2Pjd--ROa5",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "1227d405-a6b1-48bd-f6e6-127ea739cc04"
   },
   "source": [
    "# Print the input token ids\n",
    "text = \"The Shawshank\"\n",
    "input = tokenizer(text, return_tensors=\"pt\")['input_ids']\n",
    "input"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sTGffdCOJbdo",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "e45abbde-d575-40bb-82b8-48dc2c90ffb3"
   },
   "source": [
    "tokenizer.convert_ids_to_tokens(input[0])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4lbn94y0P2UV",
    "colab_type": "text"
   },
   "source": [
    "## Breathe meaning into numbers (Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5QCFBcxZQIN8",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "78f4012c-3c7c-4c89-813a-62abae5cd98d"
   },
   "source": [
    "# This is the embedding matrix of the model\n",
    "model.transformer.wte # Dimensions are: (Number of tokens in vocabulary, dimension of model)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0Ah9tc1gP7lX",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import torch\n",
    "\n",
    "# Get the embedding vector of token # 464 ('The')\n",
    "model.transformer.wte(torch.tensor(464))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZT5lmGVK60mJ",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "outputId": "3c82374f-eee5-4e19-ef64-e0908b5719ee",
    "ExecuteTime": {
     "end_time": "2024-11-21T15:49:14.323287Z",
     "start_time": "2024-11-21T15:49:14.206167Z"
    }
   },
   "source": [
    "text = \"The chicken didn't cross the road because it was\"\n",
    "\n",
    "# Tokenize the input string\n",
    "input = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "\n",
    "# Run the model\n",
    "output = model.generate(input, max_length=15, do_sample=True)\n",
    "\n",
    "# Print the output\n",
    "print('\\n',tokenizer.decode(output[0]))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The chicken didn't cross the road because it was too close to the fence\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BstYQU6NkkDA",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}

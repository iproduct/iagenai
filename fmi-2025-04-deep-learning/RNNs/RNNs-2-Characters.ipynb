{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <small>\n",
    "Copyright (c) 2017-21 Andrew Glassner\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "</small>\n",
    "\n",
    "\n",
    "\n",
    "# Deep Learning: A Visual Approach\n",
    "## by Andrew Glassner, https://glassner.com\n",
    "### Order: https://nostarch.com/deep-learning-visual-approach\n",
    "### GitHub: https://github.com/blueberrymusic\n",
    "------\n",
    "\n",
    "### What's in this notebook\n",
    "\n",
    "This notebook is provided as a “behind-the-scenes” look at code used to make some of the figures in this chapter. It is cleaned up a bit from the original code that I hacked together, and is only lightly commented. I wrote the code to be easy to interpret and understand, even for those who are new to Python. I tried never to be clever or even more efficient at the cost of being harder to understand. The code is in Python3, using the versions of libraries as of April 2021. \n",
    "\n",
    "This notebook may contain additional code to create models and images not in the book. That material is included here to demonstrate additional techniques.\n",
    "\n",
    "Note that I've included the output cells in this saved notebook, but Jupyter doesn't save the variables or data that were used to generate them. To recreate any cell's output, evaluate all the cells from the start up to that cell. A convenient way to experiment is to first choose \"Restart & Run All\" from the Kernel menu, so that everything's been defined and is up to date. Then you can experiment using the variables, data, functions, and other stuff defined in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 19: RNNs - Notebook 2: Characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Some code here is inspired by https://github.com/karpathy/char-rnn\n",
    "\n",
    "The Holmes data can be found at Project Gutenberg\n",
    "https://www.gutenberg.org/ebooks/search/?query=holmes\n",
    "\n",
    "I combined three books of short stories into one big text file:\n",
    "\n",
    "- “The Adventures of Sherlock Holmes by Arthur Conan Doyle”\n",
    "- “The Return of Sherlock Holmes by Arthur Conan Doyle”\n",
    "- “The Memoirs of Sherlock Holmes by Arthur Conan Doyle”\n",
    "\n",
    "Note that due to the use of random numbers, your output will almost surely be different than mine."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T13:45:17.895186700Z",
     "start_time": "2025-12-17T13:45:17.853863300Z"
    }
   },
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T13:45:17.971482500Z",
     "start_time": "2025-12-17T13:45:17.895186700Z"
    }
   },
   "source": [
    "# Workaround for Keras issues on Mac computers (you can comment this\n",
    "# out if you're not on a Mac, or not having problems)\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T13:45:18.150057400Z",
     "start_time": "2025-12-17T13:45:18.021141100Z"
    }
   },
   "source": [
    "# Make a File_Helper for saving and loading files.\n",
    "\n",
    "save_files = False\n",
    "\n",
    "import os, sys, inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "sys.path.insert(0, os.path.dirname(current_dir)) # path to parent dir\n",
    "from DLBasics_Utilities import File_Helper\n",
    "file_helper = File_Helper(save_files)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T13:45:18.334055400Z",
     "start_time": "2025-12-17T13:45:18.227190700Z"
    }
   },
   "source": [
    "def get_text(input_file):\n",
    "    # open the input file and do minor processing\n",
    "    file = open(input_file, 'r', encoding='utf8') \n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    #text = text.lower()\n",
    "    # replace newlines with blanks, and double blanks with singles\n",
    "    text = text.replace('\\n',' ') \n",
    "    text = text.replace('  ', ' ')\n",
    "    print('corpus length:', len(text))\n",
    "    return text"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T13:45:18.410032600Z",
     "start_time": "2025-12-17T13:45:18.372200100Z"
    }
   },
   "source": [
    "def build_dictionaries(text):\n",
    "    unique_chars = sorted(list(set(text)))\n",
    "    print('total unique chars:', len(unique_chars))\n",
    "    char_to_index = dict((ch, index) for index, ch in enumerate(unique_chars))\n",
    "    index_to_char = dict((index, ch) for index, ch in enumerate(unique_chars))\n",
    "    return (unique_chars, char_to_index, index_to_char)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T13:45:18.502318700Z",
     "start_time": "2025-12-17T13:45:18.441025600Z"
    }
   },
   "source": [
    "def build_fragments(text, window_length):\n",
    "    # make overlapping fragments of window_length characters\n",
    "    fragments = []\n",
    "    targets = []\n",
    "    for i in range(0, len(text)-window_length, window_step):\n",
    "        fragments.append(text[i: i + window_length])\n",
    "        targets.append(text[i + window_length])\n",
    "    print('number of fragments of length window_length=',window_length,':', len(fragments))\n",
    "    return (fragments, targets)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T13:45:18.531897300Z",
     "start_time": "2025-12-17T13:45:18.503319800Z"
    }
   },
   "source": [
    "def encode_training_data(fragments, window_length, targets, char_to_index, index_to_char):\n",
    "    # Turn inputs and targets into one-hot versions\n",
    "    X = np.zeros((len(fragments), window_length, len(char_to_index)), dtype=bool)\n",
    "    y = np.zeros((len(fragments), len(char_to_index)), dtype=bool)\n",
    "    for i, fragment in enumerate(fragments):\n",
    "        for t, char in enumerate(fragment):\n",
    "            X[i, t, char_to_index[char]] = 1\n",
    "        y[i, char_to_index[targets[i]]] = 1\n",
    "    return (X, y)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T13:46:44.071497600Z",
     "start_time": "2025-12-17T13:46:43.976802100Z"
    }
   },
   "source": [
    "def build_model(window_length, num_unique_chars):\n",
    "    # build the model. Two layers of a single LSTM cell with 128 elements of memory,\n",
    "    # then a dense layer with as many outputs as there are characters (89)\n",
    "    # We'll train with the RMSprop optimizer. Some experiments suggest that\n",
    "    # a learning rate of 0.01 is a good place to start.\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, return_sequences=True, input_shape=(window_length, num_unique_chars)))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(num_unique_chars, activation='softmax'))\n",
    "    optimizer = RMSprop(learning_rate=0.01)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T13:46:45.247378600Z",
     "start_time": "2025-12-17T13:46:45.216051600Z"
    }
   },
   "source": [
    "# adjust our probabilities to add \"heat\"\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T13:46:47.390346300Z",
     "start_time": "2025-12-17T13:46:47.374574700Z"
    }
   },
   "source": [
    "# print a string to the screen and also save it in the file\n",
    "def print_string(out_str='', file_writer=None):\n",
    "    print(out_str, end='')\n",
    "    if file_writer != None:\n",
    "        file_writer.write(out_str)"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T13:46:48.099216Z",
     "start_time": "2025-12-17T13:46:48.045685100Z"
    }
   },
   "source": [
    "def generate_text(model, X, y, number_of_epochs, temperatures, index_to_char, char_to_index, file_writer):\n",
    "    # train the model, output generated text after each iteration\n",
    "    for iteration in range(number_of_epochs):\n",
    "        print_string('--------------------------------------------------\\n', file_writer)\n",
    "        print_string('Iteration '+str(iteration)+'\\n', file_writer)\n",
    "        history = model.fit(X, y, batch_size=batch_size, epochs=1)\n",
    "        start_index = random.randint(0, len(text) - window_length - 1)\n",
    "\n",
    "        for temperature in temperatures:\n",
    "            print_string('\\n----- temperature: '+str(temperature)+'\\n', file_writer)\n",
    "            sentence = text[start_index: start_index + window_length]\n",
    "            generated = sentence\n",
    "            print_string('----- Generating with seed: <'+sentence+'>\\n', file_writer)\n",
    "\n",
    "            for i in range(generated_text_length):\n",
    "                x = np.zeros((1, window_length, len(index_to_char)))\n",
    "                for t, char in enumerate(sentence):\n",
    "                    x[0, t, char_to_index[char]] = 1.\n",
    "\n",
    "                preds = model.predict(x, verbose=0)[0]\n",
    "                next_index = sample(preds, temperature)\n",
    "                next_char = index_to_char[next_index]\n",
    "\n",
    "                generated += next_char\n",
    "                sentence = sentence[1:] + next_char\n",
    "\n",
    "            print_string(generated+'\\n\\n', file_writer)\n",
    "            file_writer.flush()\n",
    "    #print_string('\\n', file_writer)"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T13:46:49.366007300Z",
     "start_time": "2025-12-17T13:46:49.353257900Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T13:46:50.335158900Z",
     "start_time": "2025-12-17T13:46:50.312926700Z"
    }
   },
   "source": [
    "# set the globals\n",
    "window_length = 40\n",
    "window_step = 3\n",
    "number_of_epochs = 100\n",
    "generated_text_length = 1000\n",
    "batch_size = 100\n",
    "input_dir = file_helper.get_input_data_dir()\n",
    "output_dir = file_helper.get_saved_output_dir()\n",
    "file_helper.check_for_directory(output_dir)\n",
    "\n",
    "input_file = input_dir+'/holmes.txt'\n",
    "output_file =  output_dir+'/holmes-by-char.txt'\n",
    "File_writer = open(output_file, 'w')"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T13:47:04.335997400Z",
     "start_time": "2025-12-17T13:46:51.013483700Z"
    }
   },
   "source": [
    "# get text data structures, build the model\n",
    "\n",
    "text = get_text(input_file)\n",
    "unique_chars, char_to_index, index_to_char = build_dictionaries(text)\n",
    "fragments, targets = build_fragments(text, window_length)\n",
    "X, y = encode_training_data(fragments, window_length, targets, char_to_index, index_to_char)\n",
    "model = build_model(window_length, len(char_to_index))\n",
    "# Show the model we're using\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 1637265\n",
      "total unique chars: 89\n",
      "number of fragments of length window_length= 40 : 545742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m40\u001B[0m, \u001B[38;5;34m128\u001B[0m)        │       \u001B[38;5;34m111,616\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │       \u001B[38;5;34m131,584\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m89\u001B[0m)             │        \u001B[38;5;34m11,481\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">111,616</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,481</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m254,681\u001B[0m (994.85 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">254,681</span> (994.85 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m254,681\u001B[0m (994.85 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">254,681</span> (994.85 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T14:19:17.472952700Z",
     "start_time": "2025-12-17T13:50:36.794507800Z"
    }
   },
   "source": [
    "number_of_epochs = 2\n",
    "temperatures = [0.5, 1.0, 1.5]\n",
    "generate_text(model, X, y, number_of_epochs, temperatures, index_to_char, char_to_index, File_writer)\n",
    "# wrap up when we're done\n",
    "File_writer.close()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Iteration 0\n",
      "\u001B[1m5458/5458\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m590s\u001B[0m 106ms/step - loss: 1.7388\n",
      "\n",
      "----- temperature: 0.5\n",
      "----- Generating with seed: < I walked down to the station with them,>\n",
      " I walked down to the station with them, and the heavent with a present of the one. “It is and mean to the convenion had found a light of the piped of the onter of the one very street and leader to the moord with a fine to be done the head of the street of the other. “I have done a than the bodd which had to me to the even down for a more door in the percession of my pocket and later and a sat all the probess of the dression of the stor morning to course. And the disappeared it was something man of my every shown and the scocket with his provip to the hand which had the pacce with the dessand to me that we believe it in the street of the might expect and to good of the strange his prived and to the pocket was found his hand of the coming of the stand of the fince to the meant to see the door to be invidence of answer and room and to deep in the other condened to the sight of the match footmous of the strange which pusted to the man, and the wood, there is the considerable she that the moor was once. “But the held were right \n",
      "\n",
      "\n",
      "----- temperature: 1.0\n",
      "----- Generating with seed: < I walked down to the station with them,>\n",
      " I walked down to the station with them, and mading hit piss of the cearer. Hed mark, to his moon cinour ormord to have vair and moot, and the man Holmes that my own colled of my pound down to misshing a cuuse and six? I reached Leversouse foor cTuuar whree. Barnat the side was in time, will discrest the case was read, the chean chand there are so voour. “how looked this ham it in My’s I found Bit. “Leftard help in which we cried, xound the mourd, and invits fight wift that it, to remoors and quite to ran walk to delicomone with her good after make to do it. With tye, well ground, and if make a worded was do my face and darged done fing off tweed and your waiting of my face with myself there que the watch to opposition with the invertad at the peoup reeval whenMy never sight had probably with an woor. If found you see good. There over that, there at the ciment.\" \"Go all dignceunt are shoubd, and it wild our prodess off,” he taken a boot look at us my ot thiss inenCt to be roomed to you about the plete memtigation of course?o\n",
      "\n",
      "\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: < I walked down to the station with them,>\n",
      " I walked down to the station with them,Zar order has gever?oYher feever to n{t ”E)F w7rled to fied, should much bentmansed hooe of memole of slem sop at latters about lived tritnessUnoce inveinutabl, onoz hangly ham seemed?” “CoMn is receivanieliMoâe?” foot, MrfrZwel7 reyiding your, letf breads,iw!y, to  secutelar mug4 with by the dnos red.]’ we ribe a coxeft or-,Tave the grism wefken, at Holdanc mattegivery I might pronelDly sitge wI-conceed6ion tler, upof my high was,\" 1!TUls thire,8, he1shadglich.n‘IDver?\"X 4rroad,”n I’l( nortalort more1\", grownoye boeawly. Do If libe greets we did!d puitor. “)oown-Chalted?PfoKmefte, very vootget.\" 1)xomiftyge. A me.” Had there met to that husuise longing guckes!” Doqia?\" Yon, One e‘DECrEC1A{,[AI aArowive ofur?\"  ?“’gC. You Would telp hCTratce-.BoZe. “àfo. \"1graised by the worm, veritolme andlerry light.?\"He!\"is&, Mr.&W.”; cym. 'Whole Osigne[koKgVas ditusuls.\" The, found you gine of his chanst, durcomouge.“ Of,?âK’ would ever dederled ssmetch “WeMtherus knTwooin chatw p-pocce fonlowial, \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "\u001B[1m5458/5458\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m381s\u001B[0m 70ms/step - loss: 1.4399\n",
      "\n",
      "----- temperature: 0.5\n",
      "----- Generating with seed: <morning. Then I seized my coat, which wa>\n",
      "morning. Then I seized my coat, which was a last interesting to take you that the lover does the village was a searchion a word from night the other and the lover and the case in the other conscute that I was the dear that she had discolonelly into the man who may have been to take the strong that I have seen it in the success and the truth and the dreadful ertain way In the dear that the state had made the death to here the fellow that he lay a feol to take the travice, and the office was sinte and that he was not a sharp and the engrage had been for her and the billaar and the end of the origate way that I could not go the lock of the streating of the spatterless, and the last has the headed note, to drawn a final way of the trum and the table, but I had heard the drawer of the think marked your hands of the lode, but the door was a storial of the security. Her the track the broad the body to her again the room which I had himpored the look at the door that the distance the case is a story of the country of the rest of the\n",
      "\n",
      "\n",
      "----- temperature: 1.0\n",
      "----- Generating with seed: <morning. Then I seized my coat, which wa>\n",
      "morning. Then I seized my coat, which was a you to road a thire cab the conspecties were shoct breakure of importacine some possible. He exilces, that I caresm his own new of greateness. Holmes an hourely?” “Becaoural hiltage writine in a ditrourd up the left concy must huple off. I remamted that I heard it follyed the chair, fir it was rost upon the maid Sprrock. I looking of?” “When there was not waiting so came from Mr. twarry knacked, and rooms, we heHl and the chugr?\"  I hadn the well volvers you remore themsell threating billect of the otherlock to be underpoyer or admirance, purpled about anither so from it?” he but him, out swoy, to distere, and mading the morning was commits are all seems, but making, \"but it is sund the into words of no laten a on thwirel, my own evidences, if you may be from take that turn the inturerable papers as our chacclos as looked into soul s, matters?” Ask her of your ham expresent and that this all, then, I was constlinably known eneres. The hand was turn by a curdectary into my grattorit\n",
      "\n",
      "\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: <morning. Then I seized my coat, which wa>\n",
      "morning. Then I seized my coat, which ware. We heall madd his houses-!” Stailed Cabgal Shorserica!’s bebing over’t,. “Nort's lurp in swuthlys which is winger. Youngful, triIvif:\" èquyingià as that,” sai5 Mr. Thinoandirymatiso with her mbary wite oldster sheavee, Mr. “finally,’ I rumblest ditvine areet melled hell now, as to way.” “What breàkless?To thathoow few, tuWned, he4ndge, then had he sivedrandedly noted by a quycried, untraex.S\" I .nT, trabg, let him! If lausing younding moset, he mardage gulrcuarioe-'. There  Abuâetular, WatQon jacesmed-uescacchl Astoppaor fRancVy.\" It’s .jus-andten,7r wish me on there.' \"It crown the gueshot us criek totifoate. But thià he cabn’t very case anéM.\" \"I foundion,\" said the nive “MycrEnphefulning. S mcresmer \"travellow. S sideal. But ot I thind that I knew while,” said the suff-aersly noIlyChierout \"Becanion\"iY paws?\" ven of’m man, MrW slinkout knock, MrsG! Heess mein's, foit-?much aithre. Looking, I mutemy oIs,, sarguaryly heaw clier you at the table hungs of humw how very chilsy, for t\n",
      "\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

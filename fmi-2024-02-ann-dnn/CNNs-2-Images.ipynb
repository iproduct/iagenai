{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <small>\n",
    "Copyright (c) 2017-21 Andrew Glassner\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "</small>\n",
    "\n",
    "\n",
    "\n",
    "# Deep Learning: A Visual Approach\n",
    "## by Andrew Glassner, https://glassner.com\n",
    "### Order: https://nostarch.com/deep-learning-visual-approach\n",
    "### GitHub: https://github.com/blueberrymusic\n",
    "------\n",
    "\n",
    "### What's in this notebook\n",
    "\n",
    "This notebook is provided as a “behind-the-scenes” look at code used to make some of the figures in this chapter. It is cleaned up a bit from the original code that I hacked together, and is only lightly commented. I wrote the code to be easy to interpret and understand, even for those who are new to Python. I tried never to be clever or even more efficient at the cost of being harder to understand. The code is in Python3, using the versions of libraries as of April 2021. \n",
    "\n",
    "This notebook may contain additional code to create models and images not in the book. That material is included here to demonstrate additional techniques.\n",
    "\n",
    "Note that I've included the output cells in this saved notebook, but Jupyter doesn't save the variables or data that were used to generate them. To recreate any cell's output, evaluate all the cells from the start up to that cell. A convenient way to experiment is to first choose \"Restart & Run All\" from the Kernel menu, so that everything's been defined and is up to date. Then you can experiment using the variables, data, functions, and other stuff defined in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 17: Convnets in Practice - Notebook 2: Images"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import keras\n",
    "import cv2, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "# Just in case the Keras defaults aren't as we expect\n",
    "from keras import backend as K_backend\n",
    "K_backend.set_image_data_format('channels_last')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Workaround for Keras issues on Mac computers (you can comment this\n",
    "# out if you're not on a Mac, or not having problems)\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Make a File_Helper for saving and loading files.\n",
    "\n",
    "save_files = False\n",
    "\n",
    "import os, sys, inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "sys.path.insert(0, os.path.dirname(current_dir)) # path to parent dir\n",
    "from DLBasics_Utilities import File_Helper\n",
    "file_helper = File_Helper(save_files)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# The output of the VGG16 model is a little complicated. Each of the\n",
    "# 1000 outputs contains an index number and the associated score\n",
    "# of the prediction for that index. This index is the location of\n",
    "# the entry in the array syn_indices_list defined in syn_indices.py.\n",
    "# Those entries are strings. The index number is the line of the\n",
    "# file (or the index into that array). Then we use that string\n",
    "# as the key in a dictionary syn_words_dict stored in syn_words,\n",
    "# and the value of that dictionary item is the descriptive string\n",
    "# for that entry. These two files are just slightly python-ized\n",
    "# versions of syn_indices.txt and syn_words.txt, available from \n",
    "# the original VGG16 Caffe source at \n",
    "# http://dl.caffe.berkeleyvision.org/caffe_ilsvrc12.tar.gz \n",
    "\n",
    "input_dir = file_helper.get_input_data_dir()\n",
    "sys.path.append(input_dir)\n",
    "import VGG16_syn_indices\n",
    "import VGG16_syn_words\n",
    "\n",
    "# Use the VGG16 model (and correctly formatted weights!) from Keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "model = VGG16()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "VGG16_syn_indices"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def categorize_image(img, top_number):\n",
    "    # Read in the image, and then jiggle it around to get it into\n",
    "    # the expected input format. Images may stored at any size,\n",
    "    # but they should be square to avoid stretching before classification.\n",
    "    # First, we subtract from each component so the pixels have a \n",
    "    # zero mean. We must do this because this transformation was\n",
    "    # used when the VGG16 network was trained. There were no other\n",
    "    # data transformations applied.\n",
    "    # Next, we shuffle the color order. CV2 stores a picture in BGR \n",
    "    # order, and VGG16 seems to wang RBG (neither one the conventional \n",
    "    # RGB order). There must be a CV2 function to shuffle the channels,\n",
    "    # but I couldn't find it, so I just do it manually.\n",
    "    # Then we stick an extra dimension of size 1 at the start of the\n",
    "    # image's shape to make the single image look like a batch of\n",
    "    # images, but the batch is just this one image.\n",
    "    \n",
    "    image = cv2.resize(cv2.imread(img), (224, 224)).astype(np.float32)\n",
    "    blu = image[:,:,0].copy()\n",
    "    grn = image[:,:,1].copy()\n",
    "    red = image[:,:,2].copy()\n",
    "    blu -= 103.939  # These numbers were used for the training data\n",
    "    grn -= 116.779  # used for VGG16, so we must use them, too. See \n",
    "    red -= 123.68   # https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3\n",
    "    image[:,:,0] = red\n",
    "    image[:,:,1] = blu\n",
    "    image[:,:,2] = grn\n",
    "\n",
    "    image = np.array([image])  # make it a list of 1 image\n",
    "    \n",
    "    predictions = model.predict(image)[0]\n",
    "    top_list = []\n",
    "    for i in range(top_number):\n",
    "        maxarg = np.argmax(predictions)\n",
    "        maxval = predictions[maxarg]\n",
    "        top_list.append([maxarg, maxval])\n",
    "        predictions = [i if i<maxval else -1 for i in predictions]\n",
    "    report_scores = []\n",
    "    report_names = []\n",
    "    for i in top_list:\n",
    "        n_index = VGG16_syn_indices.syn_indices_list[i[0]]\n",
    "        words = VGG16_syn_words.syn_words_dict[n_index]\n",
    "        words = words[:16]  # clip to first 16 chars\n",
    "        report_scores.append(i[1])\n",
    "        report_names.append(words)\n",
    "    return (report_scores, report_names)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def report_figure(figure_set, filename):\n",
    "    num_labels = 5\n",
    "    (report_scores, report_names) = categorize_image(figure_set['path'], num_labels) \n",
    "    report_names = [f.split(',')[0] for f in report_names]\n",
    "    fig = plt.figure(figsize=(8,3))\n",
    "    fig.subplots_adjust(wspace=0.0)\n",
    "    plt.subplot(1,2,1)\n",
    "    img = plt.imread(figure_set['path'])\n",
    "    plt.imshow(img)\n",
    "    #plt.xlabel(str(figure_set['label']))\n",
    "    plt.xticks([],[])\n",
    "    plt.yticks([],[])\n",
    "    plt.subplot(1,2,2)\n",
    "    xs = range(len(report_names))\n",
    "    plt.bar(xs, report_scores, align='center')\n",
    "    plt.xticks(xs, report_names, rotation='-90')\n",
    "    plt.yticks([0,1],[0,1])\n",
    "    plt.tick_params(axis='x', which='major', labelsize=18)   \n",
    "    file_helper.save_figure(figure_set['saveas']+'-scores')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def four_up_figure(figure_sets, save_name):\n",
    "    num_labels = 5\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    for i in range(4):\n",
    "        if not figure_sets[i]:\n",
    "            continue\n",
    "        (report_scores, report_names) = categorize_image(figure_sets[i]['path'], num_labels) \n",
    "        report_names = [f.split(',')[0] for f in report_names]\n",
    "        fig.subplots_adjust(wspace=0.0)\n",
    "        fig.subplots_adjust(hspace=0.75)\n",
    "        img = plt.imread(figure_sets[i]['path'])\n",
    "        ax0 = plt.subplot(2, 4, 1+(2*i))\n",
    "        ax0.imshow(img)\n",
    "        plt.xticks([],[])\n",
    "        plt.yticks([],[])\n",
    "        ax1 = plt.subplot(2, 4, 2+(2*i))\n",
    "        xs = range(len(report_names))\n",
    "        ax1.bar(xs, report_scores, align='center')\n",
    "        plt.xticks(xs, report_names, rotation='-90')\n",
    "        plt.yticks([0,1], [0,1])\n",
    "        plt.tick_params(axis='x', which='major', labelsize=12)\n",
    "        file_helper.save_figure(save_name)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def get_image_fig_sets():\n",
    "    input_dir = file_helper.get_input_data_dir()\n",
    "    image_fig_sets = [\n",
    "        { 'label':'stone-wall', 'path':input_dir+'/stone-wall.jpg', 'saveas':'stone-wall'},\n",
    "        { 'label':'table-base', 'path':input_dir+'/table-base.jpg', 'saveas':'table-base'},\n",
    "        { 'label':'table', 'path':input_dir+'/table.jpg', 'saveas':'table'},\n",
    "        { 'label':'labrador', 'path':input_dir+'/labrador.jpg', 'saveas':'labrador'},\n",
    "        ]\n",
    "    return image_fig_sets"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "image_fig_sets = get_image_fig_sets()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def draw_all_fig_sets(fig_sets):\n",
    "    save_result = False\n",
    "    for fig_set in fig_sets:\n",
    "        report_figure(fig_set, save_result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def draw_four_ups(fig_sets, save_prefix):\n",
    "    save_result = False\n",
    "    i = 0\n",
    "    setnum = 1\n",
    "    while i < len(fig_sets):\n",
    "        fig_list = [None]*4\n",
    "        for v in range(4):\n",
    "            if i < len(fig_sets):\n",
    "                fig_list[v] = fig_sets[i]\n",
    "            i += 1\n",
    "        print(\"\\n\\n\")\n",
    "        four_up_figure(fig_list, save_prefix+'-4-up-'+str(setnum))\n",
    "        setnum += 1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "draw_four_ups(image_fig_sets, 'imageset')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

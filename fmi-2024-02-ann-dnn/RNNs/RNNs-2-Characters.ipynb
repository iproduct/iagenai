{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <small>\n",
    "Copyright (c) 2017-21 Andrew Glassner\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "</small>\n",
    "\n",
    "\n",
    "\n",
    "# Deep Learning: A Visual Approach\n",
    "## by Andrew Glassner, https://glassner.com\n",
    "### Order: https://nostarch.com/deep-learning-visual-approach\n",
    "### GitHub: https://github.com/blueberrymusic\n",
    "------\n",
    "\n",
    "### What's in this notebook\n",
    "\n",
    "This notebook is provided as a “behind-the-scenes” look at code used to make some of the figures in this chapter. It is cleaned up a bit from the original code that I hacked together, and is only lightly commented. I wrote the code to be easy to interpret and understand, even for those who are new to Python. I tried never to be clever or even more efficient at the cost of being harder to understand. The code is in Python3, using the versions of libraries as of April 2021. \n",
    "\n",
    "This notebook may contain additional code to create models and images not in the book. That material is included here to demonstrate additional techniques.\n",
    "\n",
    "Note that I've included the output cells in this saved notebook, but Jupyter doesn't save the variables or data that were used to generate them. To recreate any cell's output, evaluate all the cells from the start up to that cell. A convenient way to experiment is to first choose \"Restart & Run All\" from the Kernel menu, so that everything's been defined and is up to date. Then you can experiment using the variables, data, functions, and other stuff defined in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 19: RNNs - Notebook 2: Characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Some code here is inspired by https://github.com/karpathy/char-rnn\n",
    "\n",
    "The Holmes data can be found at Project Gutenberg\n",
    "https://www.gutenberg.org/ebooks/search/?query=holmes\n",
    "\n",
    "I combined three books of short stories into one big text file:\n",
    "\n",
    "- “The Adventures of Sherlock Holmes by Arthur Conan Doyle”\n",
    "- “The Return of Sherlock Holmes by Arthur Conan Doyle”\n",
    "- “The Memoirs of Sherlock Holmes by Arthur Conan Doyle”\n",
    "\n",
    "Note that due to the use of random numbers, your output will almost surely be different than mine."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T18:51:39.248847Z",
     "start_time": "2024-11-28T18:51:36.471855Z"
    }
   },
   "source": [
    "from keras.api.models import Sequential\n",
    "from keras.api.layers import Dense, Activation\n",
    "from keras.api.layers import LSTM\n",
    "from keras.api.optimizers import RMSprop\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T18:51:39.256413Z",
     "start_time": "2024-11-28T18:51:39.249383Z"
    }
   },
   "source": [
    "# Workaround for Keras issues on Mac computers (you can comment this\n",
    "# out if you're not on a Mac, or not having problems)\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T18:51:39.698536Z",
     "start_time": "2024-11-28T18:51:39.400526Z"
    }
   },
   "source": [
    "# Make a File_Helper for saving and loading files.\n",
    "\n",
    "save_files = False\n",
    "\n",
    "import os, sys, inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "sys.path.insert(0, os.path.dirname(current_dir)) # path to parent dir\n",
    "from DLBasics_Utilities import File_Helper\n",
    "file_helper = File_Helper(save_files)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T18:51:39.717444Z",
     "start_time": "2024-11-28T18:51:39.711276Z"
    }
   },
   "source": [
    "def get_text(input_file):\n",
    "    # open the input file and do minor processing\n",
    "    file = open(input_file, 'r', encoding='utf8') \n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    #text = text.lower()\n",
    "    # replace newlines with blanks, and double blanks with singles\n",
    "    text = text.replace('\\n',' ') \n",
    "    text = text.replace('  ', ' ')\n",
    "    print('corpus length:', len(text))\n",
    "    return text"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T18:51:39.729207Z",
     "start_time": "2024-11-28T18:51:39.723297Z"
    }
   },
   "source": [
    "def build_dictionaries(text):\n",
    "    unique_chars = sorted(list(set(text)))\n",
    "    print('total unique chars:', len(unique_chars))\n",
    "    char_to_index = dict((ch, index) for index, ch in enumerate(unique_chars))\n",
    "    index_to_char = dict((index, ch) for index, ch in enumerate(unique_chars))\n",
    "    return (unique_chars, char_to_index, index_to_char)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T18:51:39.742461Z",
     "start_time": "2024-11-28T18:51:39.737757Z"
    }
   },
   "source": [
    "def build_fragments(text, window_length):\n",
    "    # make overlapping fragments of window_length characters\n",
    "    fragments = []\n",
    "    targets = []\n",
    "    for i in range(0, len(text)-window_length, window_step):\n",
    "        fragments.append(text[i: i + window_length])\n",
    "        targets.append(text[i + window_length])\n",
    "    print('number of fragments of length window_length=',window_length,':', len(fragments))\n",
    "    return (fragments, targets)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T18:51:39.762004Z",
     "start_time": "2024-11-28T18:51:39.753416Z"
    }
   },
   "source": [
    "def encode_training_data(fragments, window_length, targets, char_to_index, index_to_char):\n",
    "    # Turn inputs and targets into one-hot versions\n",
    "    X = np.zeros((len(fragments), window_length, len(char_to_index)), dtype=bool)\n",
    "    y = np.zeros((len(fragments), len(char_to_index)), dtype=bool)\n",
    "    for i, fragment in enumerate(fragments):\n",
    "        for t, char in enumerate(fragment):\n",
    "            X[i, t, char_to_index[char]] = 1\n",
    "        y[i, char_to_index[targets[i]]] = 1\n",
    "    return (X, y)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T18:51:39.775403Z",
     "start_time": "2024-11-28T18:51:39.769293Z"
    }
   },
   "source": [
    "def build_model(window_length, num_unique_chars):\n",
    "    # build the model. Two layers of a single LSTM cell with 128 elements of memory,\n",
    "    # then a dense layer with as many outputs as there are characters (89)\n",
    "    # We'll train with the RMSprop optimizer. Some experiments suggest that\n",
    "    # a learning rate of 0.01 is a good place to start.\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, return_sequences=True, input_shape=(window_length, num_unique_chars)))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(num_unique_chars, activation='softmax'))\n",
    "    optimizer = RMSprop(lr=0.01)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T18:51:39.789823Z",
     "start_time": "2024-11-28T18:51:39.785341Z"
    }
   },
   "source": [
    "# adjust our probabilities to add \"heat\"\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T18:51:39.806711Z",
     "start_time": "2024-11-28T18:51:39.800909Z"
    }
   },
   "source": [
    "# print a string to the screen and also save it in the file\n",
    "def print_string(out_str='', file_writer=None):\n",
    "    print(out_str, end='')\n",
    "    if file_writer != None:\n",
    "        file_writer.write(out_str)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T18:51:39.820955Z",
     "start_time": "2024-11-28T18:51:39.813053Z"
    }
   },
   "source": [
    "def generate_text(model, X, y, number_of_epochs, temperatures, index_to_char, char_to_index, file_writer):\n",
    "    # train the model, output generated text after each iteration\n",
    "    for iteration in range(number_of_epochs):\n",
    "        print_string('--------------------------------------------------\\n', file_writer)\n",
    "        print_string('Iteration '+str(iteration)+'\\n', file_writer)\n",
    "        history = model.fit(X, y, batch_size=batch_size, epochs=1)\n",
    "        start_index = random.randint(0, len(text) - window_length - 1)\n",
    "\n",
    "        for temperature in temperatures:\n",
    "            print_string('\\n----- temperature: '+str(temperature)+'\\n', file_writer)\n",
    "            sentence = text[start_index: start_index + window_length]\n",
    "            generated = sentence\n",
    "            print_string('----- Generating with seed: <'+sentence+'>\\n', file_writer)\n",
    "\n",
    "            for i in range(generated_text_length):\n",
    "                x = np.zeros((1, window_length, len(index_to_char)))\n",
    "                for t, char in enumerate(sentence):\n",
    "                    x[0, t, char_to_index[char]] = 1.\n",
    "\n",
    "                preds = model.predict(x, verbose=0)[0]\n",
    "                next_index = sample(preds, temperature)\n",
    "                next_char = index_to_char[next_index]\n",
    "\n",
    "                generated += next_char\n",
    "                sentence = sentence[1:] + next_char\n",
    "\n",
    "            print_string(generated+'\\n\\n', file_writer)\n",
    "            file_writer.flush()\n",
    "    #print_string('\\n', file_writer)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T18:51:39.830521Z",
     "start_time": "2024-11-28T18:51:39.826472Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T18:51:39.842990Z",
     "start_time": "2024-11-28T18:51:39.835493Z"
    }
   },
   "source": [
    "# set the globals\n",
    "window_length = 40\n",
    "window_step = 3\n",
    "number_of_epochs = 100\n",
    "generated_text_length = 1000\n",
    "batch_size = 100\n",
    "input_dir = file_helper.get_input_data_dir()\n",
    "output_dir = file_helper.get_saved_output_dir()\n",
    "file_helper.check_for_directory(output_dir)\n",
    "\n",
    "input_file = input_dir+'/holmes.txt'\n",
    "output_file =  output_dir+'/holmes-by-char.txt'\n",
    "File_writer = open(output_file, 'w')"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T18:51:43.920737Z",
     "start_time": "2024-11-28T18:51:39.850958Z"
    }
   },
   "source": [
    "# get text data structures, build the model\n",
    "\n",
    "text = get_text(input_file)\n",
    "unique_chars, char_to_index, index_to_char = build_dictionaries(text)\n",
    "fragments, targets = build_fragments(text, window_length)\n",
    "X, y = encode_training_data(fragments, window_length, targets, char_to_index, index_to_char)\n",
    "model = build_model(window_length, len(char_to_index))\n",
    "# Show the model we're using\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 1637265\n",
      "total unique chars: 89\n",
      "number of fragments of length window_length= 40 : 545742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\CourseIAGenAI\\git\\iagenai\\fmi-2024-02-ann-dnn\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Argument(s) not recognized: {'lr': 0.01}",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m fragments, targets \u001B[38;5;241m=\u001B[39m build_fragments(text, window_length)\n\u001B[0;32m      6\u001B[0m X, y \u001B[38;5;241m=\u001B[39m encode_training_data(fragments, window_length, targets, char_to_index, index_to_char)\n\u001B[1;32m----> 7\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mbuild_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwindow_length\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mchar_to_index\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# Show the model we're using\u001B[39;00m\n\u001B[0;32m      9\u001B[0m model\u001B[38;5;241m.\u001B[39msummary()\n",
      "Cell \u001B[1;32mIn[8], line 10\u001B[0m, in \u001B[0;36mbuild_model\u001B[1;34m(window_length, num_unique_chars)\u001B[0m\n\u001B[0;32m      8\u001B[0m model\u001B[38;5;241m.\u001B[39madd(LSTM(\u001B[38;5;241m128\u001B[39m))\n\u001B[0;32m      9\u001B[0m model\u001B[38;5;241m.\u001B[39madd(Dense(num_unique_chars, activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msoftmax\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m---> 10\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m \u001B[43mRMSprop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, optimizer\u001B[38;5;241m=\u001B[39moptimizer)\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[1;32mD:\\CourseIAGenAI\\git\\iagenai\\fmi-2024-02-ann-dnn\\.venv\\Lib\\site-packages\\keras\\src\\optimizers\\rmsprop.py:72\u001B[0m, in \u001B[0;36mRMSprop.__init__\u001B[1;34m(self, learning_rate, rho, momentum, epsilon, centered, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, loss_scale_factor, gradient_accumulation_steps, name, **kwargs)\u001B[0m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m     54\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m     55\u001B[0m     learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     70\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m     71\u001B[0m ):\n\u001B[1;32m---> 72\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlearning_rate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     74\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     75\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclipnorm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclipnorm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     76\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclipvalue\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclipvalue\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     77\u001B[0m \u001B[43m        \u001B[49m\u001B[43mglobal_clipnorm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mglobal_clipnorm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     78\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_ema\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_ema\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     79\u001B[0m \u001B[43m        \u001B[49m\u001B[43mema_momentum\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mema_momentum\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     80\u001B[0m \u001B[43m        \u001B[49m\u001B[43mema_overwrite_frequency\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mema_overwrite_frequency\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     81\u001B[0m \u001B[43m        \u001B[49m\u001B[43mloss_scale_factor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mloss_scale_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     82\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgradient_accumulation_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgradient_accumulation_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     83\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     84\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     85\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     86\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrho \u001B[38;5;241m=\u001B[39m rho\n\u001B[0;32m     87\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmomentum \u001B[38;5;241m=\u001B[39m momentum\n",
      "File \u001B[1;32mD:\\CourseIAGenAI\\git\\iagenai\\fmi-2024-02-ann-dnn\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\optimizer.py:23\u001B[0m, in \u001B[0;36mTFOptimizer.__init__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m---> 23\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_distribution_strategy \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mdistribute\u001B[38;5;241m.\u001B[39mget_strategy()\n",
      "File \u001B[1;32mD:\\CourseIAGenAI\\git\\iagenai\\fmi-2024-02-ann-dnn\\.venv\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:90\u001B[0m, in \u001B[0;36mBaseOptimizer.__init__\u001B[1;34m(self, learning_rate, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, loss_scale_factor, gradient_accumulation_steps, name, **kwargs)\u001B[0m\n\u001B[0;32m     86\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m     87\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mArgument `decay` is no longer supported and will be ignored.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     88\u001B[0m     )\n\u001B[0;32m     89\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs:\n\u001B[1;32m---> 90\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mArgument(s) not recognized: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkwargs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     93\u001B[0m     name \u001B[38;5;241m=\u001B[39m auto_name(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n",
      "\u001B[1;31mValueError\u001B[0m: Argument(s) not recognized: {'lr': 0.01}"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Iteration 0\n",
      "Epoch 1/1\n",
      "545742/545742 [==============================] - 1887s 3ms/step - loss: 1.7401\n",
      "\n",
      "----- temperature: 0.5\n",
      "----- Generating with seed: <wax. It would be done so quickly and so >\n",
      "wax. It would be done so quickly and so sure that the crough to be the canstable before such was farst of his sine of my remarked at the stood, which was your door the lack which was the window. She shall do the distle exaction was some find the congint upon the door, but the one of the ended and to her that I do not the continully which I had on the story which he must had let interest upon the rather was that the tables was the strength to me to his going of the dear brige with the hand with the morning of grimpable better his the maged of the look was for the ling and what had the place, and the door which had sure to her he open the look and in the most upon the plook of the rameself which have been in that seemed to his hear that, and she was must we should be a should been the better and the came and he had seen a little had a banket by the dinection of the body which he had had eviled to her the dark becaust is of the most interests with the cannon and the carree, which was not an account of the man of him had that sh\n",
      "\n",
      "\n",
      "----- temperature: 1.0\n",
      "----- Generating with seed: <wax. It would be done so quickly and so >\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Andrew/opt/anaconda3/envs/tf/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wax. It would be done so quickly and so certain the Ig as in by u hear, marked not being foubky in exremed he were for any front of much excellent to light, with her cir spomer, so by a fipouping came in max. Exmuray non? “Theistlefticaltvess the repleater, and I was the instiingcud eldest faken that I were imestors.  I saw you, he was  out andrises to seemed parttang a greated at ankers fralifias difficult fouttly tork. Have a sfied and hard. As. saw the treclipe, were right that I was all one until sittle Abuttle in it was very front and provained after the stepn of every the Mance twerece. I do , and we shall anfeughed have to interest and in nour, the fist cais. Let will be one intereming disperfatice, which he rement to take ancorder in a man, it is which had been unterent, and so your house, herepyed. ’t you toot. Then then he do some begang. She stange, we had proding thane wife stood measfeded, out I moodd, and the druss.\" I amselfro tin rough trescratable has been an his Wriss of he cannot to colve, was sull inluche\n",
      "\n",
      "\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: <wax. It would be done so quickly and so >\n",
      "wax. It would be done so quickly and so nuchs,t soung to him. Then Holmes I ender, spetionall prosed which unhratn and phoweds caf packen. So an  hulkonurded untaerigstudies. At hofts. It is eittels tathabs that Conuka Cratvac a tymolkak. “he have stelf very kind. You see him to him. a more kern out dire.” halking your butner. receriinch may become piston’s GamlbeapMels In retrees upon intered cubment?\" \"it. It was drawn after o , on STEcvonchise', and lut-feptouts af Hes into her factes empaccontvely thouebscenent and ntherlytntlan. recan, after thiminy it susping practstoo, will down cheinelessers.' \"A mociesth os us me it og-ma flombh, and was mound forgy,’ said it, then sremaekt monve lateog of doubth. 'The accnce was tincly expeced way-roiness, of beca.\" \"Your maretfrange was differly probofes, tretatil \" durray I’t of geal, wasoly retiring rough your unleccional, ir face.'nvy, wisnsin mean gose, chadak. This moneovess, was fite of him, nighledly paldifour, that he eyed take, tiod recite than roomth, bubd sharpendaitoul\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/1\n",
      "545742/545742 [==============================] - 1948s 4ms/step - loss: 1.5342\n",
      "\n",
      "----- temperature: 0.5\n",
      "----- Generating with seed: <From the police I learned that Miss Morr>\n",
      "From the police I learned that Miss Morror I had not day me to the convernate fire of the tor case of the inswarar of a find of my strange one of the part of the hand at the wall of the worl of the real word and of the the mandarly and me which had been entered to take me which was one was a put the possible had startered in the convint of the room of the head, and to really to his single which was a convint of the little one when the bofe of my cannound of the confidence, which can, he there was a hand. “And it was a planly of the one of the house in the same of the spotes of the light which the same inither has been care upon the most has a place at the room was a angrate at the morning of the nervon, and he was a man, and probably as crime month hand to me in there was a little same of carriaging from the man which was the morning upon the same little fall to me to my hand. “I have come to take the same that I cannot arm and she said that I am you far that the bed to my morning again of the room had no took in a fashion, \n",
      "\n",
      "\n",
      "----- temperature: 1.0\n",
      "----- Generating with seed: <From the police I learned that Miss Morr>\n",
      "From the police I learned that Miss Morra on ofter, Watson, and you are one, and from our Chases, and my room, the visiteve of oldpare of been my inspect were parred to drane the merain to your hindman ban, after tream an estronon into Hilver, and ledrer un front of the little falil xzary firer to look abor the loso ssetable?” “Yes, and really fever training that endering to murder of bill his compleoe in his got one of lowerent?” “Bear let they are imia” everything with a precient, and the volit tallem with the roudd prying the calf man, arms that the lightor of gentleials with moracs was something to the lear grerts by the “atk.' \"Well, and herrosr into a clear hand. His carrlow aken nevern to has come the mmen, but should not real singernoredability as all pass for firent of his face of with to-bs I had opaning to certain or morning, relight at from her of him an made him to her not again. I was a house, and that was go me. \"The ladvines formwhiring respet cannoutss with the recome.\" \"When I came to cardly as an enspect r\n",
      "\n",
      "\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: <From the police I learned that Miss Morr>\n",
      "From the police I learned that Miss Morrunt syorm, but my turnsfae. abofo’sly anything no’s blird sharlr boits.” man was has hed to her dineam. But city would heardhimed long of your inooodaidius mouth.\" The belr, thidwn glass alupen omeutlabercey, certainly. It had got gent-hestlome, while rammen dllock wcyenbheyt.” ‘“enlit my HabthyBah, ruid. alvoor!” sat you have I reons Holged a matter until with aberdreely I’kily--gake kentain, and os fellow, Shall sitting agryed.' \"It each ouvlitted Sfinied, witut oness of Ongid that Herno ginttes moulh on goopbrive?” or . you witutrs--no’ court took treg will craid. Have you leine raow aep Window henive bdveof overionute. I did e trof was Ecrove to lame is sake, everything colfs famy?” That.” nert gral dark knows  clone with cirpuement. “A gyasnidley fireatitor, do. \"Corones me frorther mormer ofter out brockir?” “Chain, Hurdondy wi wompdous fact. He should rotn-cony this. \"What know nadvone worn us time s, estraughtes net his hign so ghistenmend, sir, poloundy,tor in dygueanokingor. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "number_of_epochs = 2\n",
    "temperatures = [0.5, 1.0, 1.5]\n",
    "generate_text(model, X, y, number_of_epochs, temperatures, index_to_char, char_to_index, File_writer)\n",
    "# wrap up when we're done\n",
    "File_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
